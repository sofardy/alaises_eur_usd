#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£—Ç–∏–ª—ñ—Ç–∏ –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó —Ç–∞ –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö
"""

import pandas as pd
import numpy as np
from datetime import datetime
import warnings
from config import Config

class DataValidator:
    """–ö–ª–∞—Å –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö"""
    
    def __init__(self):
        self.config = Config()
    
    def validate_csv_file(self, file_path):
        """–í–∞–ª—ñ–¥–∞—Ü—ñ—è CSV —Ñ–∞–π–ª—É"""
        try:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —ñ—Å–Ω—É—î —Ñ–∞–π–ª
            df = pd.read_csv(file_path, nrows=5)  # –ß–∏—Ç–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤
            
            print(f"‚úÖ –§–∞–π–ª –∑–Ω–∞–π–¥–µ–Ω–æ: {file_path}")
            print(f"üìä –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫
            if len(df.columns) < 6:
                print("‚ö†Ô∏è  –£–≤–∞–≥–∞: –ú–µ–Ω—à–µ 6 –∫–æ–ª–æ–Ω–æ–∫. –û—á—ñ–∫—É—î—Ç—å—Å—è: Date, Time, Open, High, Low, Close, Volume")
                return False
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∏ —Ç–∞ —á–∞—Å—É –≤ –ø–µ—Ä—à–∏—Ö —Ä—è–¥–∫–∞—Ö
            if len(df) > 0:
                first_row = df.iloc[0]
                print(f"üìÖ –ü—Ä–∏–∫–ª–∞–¥ –¥–∞—Ç–∏: {first_row.iloc[0]}")
                print(f"‚è∞ –ü—Ä–∏–∫–ª–∞–¥ —á–∞—Å—É: {first_row.iloc[1]}")
                print(f"üí∞ –ü—Ä–∏–∫–ª–∞–¥ —Ü—ñ–Ω: O={first_row.iloc[2]}, H={first_row.iloc[3]}, L={first_row.iloc[4]}, C={first_row.iloc[5]}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ —Ñ–∞–π–ª—É: {e}")
            return False
    
    def validate_data_quality(self, df):
        """–í–∞–ª—ñ–¥–∞—Ü—ñ—è —è–∫–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö"""
        issues = []
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞ –ø—Ä–æ–ø—É—â–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        missing_values = df.isnull().sum()
        if missing_values.sum() > 0:
            issues.append(f"–ü—Ä–æ–ø—É—â–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è: {missing_values.to_dict()}")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ª–æ–≥—ñ—á–Ω—ñ—Å—Ç—å —Ü—ñ–Ω (High >= Low, Open/Close –º—ñ–∂ High/Low)
        invalid_ohlc = ((df['High'] < df['Low']) | 
                       (df['Open'] > df['High']) | (df['Open'] < df['Low']) |
                       (df['Close'] > df['High']) | (df['Close'] < df['Low'])).sum()
        
        if invalid_ohlc > 0:
            issues.append(f"–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω—ñ OHLC –¥–∞–Ω—ñ: {invalid_ohlc} —Ä—è–¥–∫—ñ–≤")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞ –¥—É–±–ª—ñ–∫–∞—Ç–∏ —á–∞—Å—É
        duplicates = df['Datetime'].duplicated().sum()
        if duplicates > 0:
            issues.append(f"–î—É–±–ª—ñ–∫–∞—Ç–∏ —á–∞—Å—É: {duplicates} —Ä—è–¥–∫—ñ–≤")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞ —Ä–æ–∑—Ä–∏–≤–∏ –≤ —á–∞—Å—ñ (–±—ñ–ª—å—à–µ 1 —Ö–≤–∏–ª–∏–Ω–∏)
        time_diff = df['Datetime'].diff()
        large_gaps = (time_diff > pd.Timedelta(minutes=5)).sum()
        if large_gaps > 0:
            issues.append(f"–í–µ–ª–∏–∫—ñ —Ä–æ–∑—Ä–∏–≤–∏ –≤ –¥–∞–Ω–∏—Ö (>5 —Ö–≤): {large_gaps}")
        
        if issues:
            print("‚ö†Ô∏è  –ó–Ω–∞–π–¥–µ–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏ –∑ —è–∫—ñ—Å—Ç—é –¥–∞–Ω–∏—Ö:")
            for issue in issues:
                print(f"   - {issue}")
            return False
        else:
            print("‚úÖ –Ø–∫—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö —Ö–æ—Ä–æ—à–∞")
            return True
    
    def get_data_statistics(self, df):
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∞–Ω–∏—Ö"""
        stats = {
            'total_records': len(df),
            'date_range': f"{df['Datetime'].min()} - {df['Datetime'].max()}",
            'trading_days': df['Datetime'].dt.date.nunique(),
            'avg_spread': ((df['High'] - df['Low']) / self.config.PIP_SIZE).mean(),
            'price_range': f"{df[['Open', 'High', 'Low', 'Close']].min().min():.5f} - {df[['Open', 'High', 'Low', 'Close']].max().max():.5f}"
        }
        
        print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–∏—Ö:")
        print(f"   –í—Å—å–æ–≥–æ –∑–∞–ø–∏—Å—ñ–≤: {stats['total_records']:,}")
        print(f"   –ü–µ—Ä—ñ–æ–¥: {stats['date_range']}")
        print(f"   –¢–æ—Ä–≥–æ–≤–∏—Ö –¥–Ω—ñ–≤: {stats['trading_days']}")
        print(f"   –°–µ—Ä–µ–¥–Ω—ñ–π —Å–ø—Ä–µ–¥: {stats['avg_spread']:.1f} –ø—É–Ω–∫—Ç—ñ–≤")
        print(f"   –î—ñ–∞–ø–∞–∑–æ–Ω —Ü—ñ–Ω: {stats['price_range']}")
        
        return stats

def validate_input_file(file_path):
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó"""
    print("üîç –í–ê–õ–Ü–î–ê–¶–Ü–Ø –í–•–Ü–î–ù–ò–• –î–ê–ù–ò–•")
    print("=" * 30)
    
    validator = DataValidator()
    
    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–∞–π–ª—É
    if not validator.validate_csv_file(file_path):
        return False
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
    try:
        df = pd.read_csv(file_path, header=None, names=Config.INPUT_COLUMNS)
        df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format=Config.DATETIME_FORMAT)
        df['Datetime'] = df['Datetime'] + pd.Timedelta(hours=Config.UTC_OFFSET)
        df = df[Config.REQUIRED_COLUMNS].copy()
        
        # –í–∞–ª—ñ–¥–∞—Ü—ñ—è —è–∫–æ—Å—Ç—ñ
        quality_ok = validator.validate_data_quality(df)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        validator.get_data_statistics(df)
        
        return quality_ok
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –¥–∞–Ω–∏—Ö: {e}")
        return False

if __name__ == "__main__":
    validate_input_file(Config.DEFAULT_INPUT_FILE)
